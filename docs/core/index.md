# Gemini CLI 核心

Gemini CLI 的核心套件 (`packages/core`) 是 Gemini CLI 的後端部分，負責處理與 Gemini API 的通訊、管理工具，以及處理來自 `packages/cli` 的請求。有關 Gemini CLI 的總覽，請參閱 [主要文件頁面](../index.md)。

## 導覽本節

- **[核心工具 API](./tools-api.md):** 關於工具如何被核心定義、註冊和使用的資訊。

## 核心的角色

Gemini CLI 的 `packages/cli` 部分提供使用者介面，而 `packages/core` 則負責：

- **Gemini API 互動：** 安全地與 Google Gemini API 通訊、傳送使用者提示，並接收模型回應。
- **提示工程：** 為 Gemini 模型建構有效的提示，可能包含對話歷史記錄、工具定義，以及來自 `GEMINI.md` 檔案的指令性情境。
- **工具管理與調度：**
  - 註冊可用的工具 (例如：檔案系統工具、shell 指令執行)。
  - 解譯來自 Gemini 模型的工具使用請求。
  - 使用提供的參數執行請求的工具。
  - 將工具執行結果回傳給 Gemini 模型以進行進一步處理。
- **對話階段與狀態管理：** 追蹤對話狀態，包括歷史記錄以及連貫互動所需的任何相關情境。
 - **設定：** 管理核心特定的設定，例如 API 金鑰存取、模型選擇和工具設定。

## 安全性考量

核心在安全性方面扮演著至關重要的角色：

- **API 金鑰管理：** 它處理 `GEMINI_API_KEY` 並確保在與 Gemini API 通訊時安全地使用它。
 - **工具執行：** 當工具與本機系統互動時 (例如 `run_shell_command`)，核心 (及其底層的工具實作) 必須謹慎操作，通常會採用沙盒機制來防止意外的修改。

## 對話歷史壓縮

為確保長對話不會超過 Gemini 模型的 token 限制，核心包含一個對話歷史壓縮功能。

當對話接近所設定模型的 token 限制時，核心會在將對話歷史傳送給模型之前自動進行壓縮。這種壓縮的設計旨在不損失傳達的資訊，但會減少使用的 token 總數。

您可以在 [Google AI 文件](https://ai.google.dev/gemini-api/docs/models) 中找到每個模型的 token 限制。

## 模型備援機制

Gemini CLI 包含一個模型備援機制，以確保即使預設的「pro」模型受到速率限制，您仍然可以繼續使用 CLI。

如果您正在使用預設的「pro」模型，且 CLI 偵測到您受到速率限制，它會在本機的對話階段中自動切換到「flash」模型。這讓您可以不間斷地繼續工作。

## 檔案探索服務

檔案探索服務負責在專案中尋找與當前情境相關的檔案。它被 `@` 指令以及其他需要存取檔案的工具所使用。

## 記憶體探索服務

記憶體探索服務負責尋找並載入為模型提供情境的 `GEMINI.md` 檔案。它以階層式的方式搜尋這些檔案，從目前的工作目錄開始，向上移動到專案根目錄和使用者的家目錄。它也會搜尋子目錄。

這讓您可以擁有全域、專案層級和元件層級的情境檔案，這些檔案會被結合起來，為模型提供最相關的資訊。

您可以使用 [`/memory` 指令](../cli/commands.md) 來 `show`、`add` 和 `refresh` 已載入的 `GEMINI.md` 檔案內容。
